{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are working in module directory\n",
    "repo_root = !git rev-parse --show-toplevel\n",
    "module_path = repo_root[0] + \"/backend/heatflask\"\n",
    "%cd $module_path\n",
    "\n",
    "# Make cells wider\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92864eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile Index.py \n",
    "\"\"\"\n",
    "***  For Jupyter notebook ***\n",
    "Paste one of these Jupyter magic directives to the top of a cell\n",
    " and run it, to do these things:\n",
    "    %%cython --annotate    # Compile and run the cell\n",
    "    %load Index.py         # Load Index.py file into this (empty) cell\n",
    "    %%writefile Index.py   # Write the contents of this cell to Index.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import polyline\n",
    "import numpy as np\n",
    "from logging import getLogger\n",
    "import datetime\n",
    "import time\n",
    "import asyncio\n",
    "from pymongo import DESCENDING\n",
    "\n",
    "from import DataAPIs\n",
    "from DataAPIs import db\n",
    "import Strava\n",
    "import Utility\n",
    "\n",
    "log = getLogger(__name__)\n",
    "log.setLevel(\"DEBUG\")\n",
    "log.propagate = True\n",
    "\n",
    "COLLECTION_NAME = \"index\"\n",
    "\n",
    "SECS_IN_HOUR = 60 * 60\n",
    "SECS_IN_DAY = 24 * SECS_IN_HOUR\n",
    "\n",
    "# How long we store Index entry in MongoDB\n",
    "INDEX_TTL = int(os.environ.get(\"INDEX_TTL\", 10)) * SECS_IN_DAY\n",
    "\n",
    "\n",
    "class Box:\n",
    "    collection = None\n",
    "\n",
    "\n",
    "myBox = Box()\n",
    "\n",
    "\n",
    "async def get_collection():\n",
    "    if myBox.collection is None:\n",
    "        myBox.collection = await DataAPIs.init_collection(\n",
    "            COLLECTION_NAME, ttl=INDEX_TTL\n",
    "        )\n",
    "    return myBox.collection\n",
    "\n",
    "\n",
    "def polyline_bounds(poly):\n",
    "    try:\n",
    "        latlngs = np.array(polyline.decode(poly), dtype=np.float32)\n",
    "    except Exception:\n",
    "        return\n",
    "\n",
    "    lats = latlngs[:, 0]\n",
    "    lngs = latlngs[:, 1]\n",
    "\n",
    "    return {\n",
    "        \"SW\": (float(lats.min()), float(lngs.min())),\n",
    "        \"NE\": (float(lats.max()), float(lngs.max())),\n",
    "    }\n",
    "\n",
    "\n",
    "# MongoDB short field names speed up data transfer to/from\n",
    "# remote DB server\n",
    "ACTIVITY_ID = \"_id\"\n",
    "TIMESTAMP = \"ts\"\n",
    "USER_ID = \"U\"\n",
    "ACTIVITY_NAME = \"N\"\n",
    "DISTANCE_METERS = \"D\"\n",
    "TIME_SECONDS = \"T\"\n",
    "ACTIVITY_TYPE = \"t\"\n",
    "UTC_START_TIME = \"s\"\n",
    "UTC_LOCAL_OFFSET = \"o\"\n",
    "N_ATHLETES = \"#a\"\n",
    "N_PHOTOS = \"#p\"\n",
    "FLAG_COMMUTE = \"c\"\n",
    "FLAG_PRIVATE = \"p\"\n",
    "LATLNG_BOUNDS = \"B\"\n",
    "VISIBILITY = \"v\"\n",
    "\n",
    "\n",
    "# see https://developers.strava.com/docs/reference/#api-models-SummaryActivity\n",
    "def mongo_doc(\n",
    "    # From Strava SummaryActivity record\n",
    "    id=None,\n",
    "    athlete=None,\n",
    "    name=None,\n",
    "    distance=None,\n",
    "    moving_time=None,\n",
    "    elapsed_time=None,\n",
    "    type=None,\n",
    "    start_date=None,\n",
    "    utc_offset=None,\n",
    "    athlete_count=None,\n",
    "    total_photo_count=None,\n",
    "    map=None,\n",
    "    commute=None,\n",
    "    private=None,\n",
    "    visibility=None,\n",
    "    # my additions\n",
    "    _id=None,\n",
    "    ts=None,\n",
    "    **and_more\n",
    "):\n",
    "    if not (start_date and map and map.get(\"summary_polyline\")):\n",
    "        return\n",
    "\n",
    "    utc_start_time = int(Utility.to_datetime(start_date).timestamp())\n",
    "    return Utility.cleandict(\n",
    "        {\n",
    "            TIMESTAMP: ts or datetime.datetime.utcnow(),\n",
    "            ACTIVITY_ID: int(_id or id),\n",
    "            USER_ID: int(athlete[\"id\"]),\n",
    "            ACTIVITY_NAME: name,\n",
    "            DISTANCE_METERS: distance,\n",
    "            TIME_SECONDS: elapsed_time,\n",
    "            ACTIVITY_TYPE: type,\n",
    "            UTC_START_TIME: utc_start_time,\n",
    "            UTC_LOCAL_OFFSET: utc_offset,\n",
    "            N_ATHLETES: athlete_count,\n",
    "            N_PHOTOS: total_photo_count,\n",
    "            VISIBILITY: visibility,\n",
    "            FLAG_COMMUTE: commute,\n",
    "            FLAG_PRIVATE: private,\n",
    "            LATLNG_BOUNDS: polyline_bounds(map[\"summary_polyline\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "## **************************************\n",
    "IMPORT_FLAG_PREFIX = \"I:\"\n",
    "IMPORT_FLAG_TTL = 20  # secods\n",
    "\n",
    "def import_flag_key(uid):\n",
    "    return  f\"{IMPORT_FLAG_PREFIX}{uid}\"\n",
    "\n",
    "async def set_import_flag(user_id, val):\n",
    "    await db.redis.setex(import_flag_key(user_id), IMPORT_FLAG_TTL, val)\n",
    "    log.debug(f\"{user_id} import flag set to %s\", val)\n",
    "\n",
    "async def clear_import_flag(user_id):\n",
    "    await db.redis.delete(import_flag_key(user_id))\n",
    "    log.debug(f\"{user_id} import flag unset\")\n",
    "    \n",
    "async def check_import_flag(user_id):\n",
    "    return await db.redis.get(import_flag_key(user_id))\n",
    "\n",
    "## **************************************\n",
    "\n",
    "async def import_user_entries(**user):\n",
    "    t0 = time.perf_counter()\n",
    "    uid = int(user[\"_id\"])\n",
    "\n",
    "    await set_import_flag(uid, \"importing index...\")\n",
    "    \n",
    "    strava = Strava.AsyncClient(uid, **user[\"auth\"])\n",
    "    await strava.update_access_token()\n",
    "    now = datetime.datetime.utcnow()\n",
    "    \n",
    "    docs = []\n",
    "    count = 0\n",
    "    async for A in strava.get_index():\n",
    "        if A is not None:\n",
    "            docs.append(mongo_doc(**A, ts=now))\n",
    "            count += 1\n",
    "            if count % Strava.PER_PAGE == 0:\n",
    "                await set_import_flag(uid, count)\n",
    "                \n",
    "#     docs = [mongo_doc(**A, ts=now) async for A in strava.get_index() if A is not None]\n",
    "    docs = filter(None, docs)\n",
    "    t1 = time.perf_counter()\n",
    "    fetch_time = (t1 - t0) * 1000\n",
    "    \n",
    "    if not docs:\n",
    "        return\n",
    "    \n",
    "    index = await get_collection()\n",
    "    await delete_user_entries(**user)\n",
    "    insert_result = await index.insert_many(docs, ordered=False)\n",
    "    insert_time = (time.perf_counter() - t1) * 1000\n",
    "    count = len(insert_result.inserted_ids)\n",
    "    \n",
    "    await clear_import_flag(uid)\n",
    "    log.debug(\n",
    "        \"fetched %s entries in %dms, insert_many %dms\", count, fetch_time, insert_time\n",
    "    )\n",
    "\n",
    "\n",
    "async def delete_user_entries(**user):\n",
    "    uid = int(user[\"_id\"])\n",
    "    index = await get_collection()\n",
    "    return await index.delete_many({USER_ID: int(uid)})\n",
    "\n",
    "async def count_user_entries(**user):\n",
    "    uid = int(user[\"_id\"])\n",
    "    index = await get_collection()\n",
    "    return await index.count_documents({USER_ID: int(uid)})\n",
    "\n",
    "async def has_user_entries(**user):\n",
    "    uid = int(user[\"_id\"])\n",
    "    index = await get_collection()\n",
    "    return not not (await index.find_one({USER_ID: int(uid)}))\n",
    "\n",
    "SORT_SPECS = [(UTC_START_TIME, DESCENDING)]\n",
    "\n",
    "\n",
    "async def query(\n",
    "    user_id=None,\n",
    "    activity_ids=None,\n",
    "    exclude_ids=None,\n",
    "    after=None,\n",
    "    before=None,\n",
    "    limit=None,\n",
    "    activity_type=None,\n",
    "    commute=None,\n",
    "    private=None,\n",
    "    visibility=None,\n",
    "    #\n",
    "    update_ts=True,\n",
    "):\n",
    "    query = {}\n",
    "    projection = None\n",
    "\n",
    "    if activity_ids:\n",
    "        activity_ids = set(int(aid) for aid in activity_ids)\n",
    "\n",
    "    if exclude_ids:\n",
    "        exclude_ids = set(int(aid) for aid in exclude_ids)\n",
    "\n",
    "    limit = int(limit) if limit else 0\n",
    "\n",
    "    if user_id:\n",
    "        query[USER_ID] = int(user_id)\n",
    "        projection = {USER_ID: False}\n",
    "\n",
    "    if before or after:\n",
    "        query[UTC_START_TIME] = Utility.cleandict(\n",
    "            {\n",
    "                \"$lt\": None if before is None else Utility.to_epoch(before),\n",
    "                \"$gte\": None if after is None else Utility.to_epoch(after),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if activity_ids:\n",
    "        query[ACTIVITY_ID] = {\"$in\": activity_ids}\n",
    "\n",
    "    if activity_type:\n",
    "        query[ACTIVITY_TYPE] = {\"$in\": activity_type}\n",
    "\n",
    "    if visibility:\n",
    "        # [\"everyone\", \"followers\", \"only_me\"]\n",
    "        query[VISIBILITY] = {\"$in\": visibility}\n",
    "\n",
    "    if private is not None:\n",
    "        query[FLAG_PRIVATE] = private\n",
    "\n",
    "    if commute is not None:\n",
    "        query[FLAG_COMMUTE] = commute\n",
    "\n",
    "    to_delete = None\n",
    "\n",
    "    index = await get_collection()\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    if exclude_ids:\n",
    "        t0 = time.perf_counter()\n",
    "        cursor = index.find(\n",
    "            filter=query,\n",
    "            projection={ACTIVITY_ID: True},\n",
    "            sort=SORT_SPECS,\n",
    "            limit=limit,\n",
    "        )\n",
    "\n",
    "        # These are the ids of activities that matched the query\n",
    "        query_ids = set([doc[ACTIVITY_ID] async for doc in cursor])\n",
    "\n",
    "        to_fetch = list(query_ids - exclude_ids)\n",
    "        to_delete = list(exclude_ids - query_ids)\n",
    "\n",
    "        result[\"triage\"] = to_delete\n",
    "        query = {ACTIVITY_ID: {\"$in\": to_fetch}}\n",
    "\n",
    "        elapsed = (time.perf_counter() - t0) * 1000\n",
    "        log.debug(\"queried %d ids in %dms\", len(query_ids), elapsed)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    cursor = index.find(\n",
    "        filter=query,\n",
    "        projection=projection,\n",
    "        sort=SORT_SPECS,\n",
    "        limit=limit,\n",
    "    )\n",
    "\n",
    "    docs = await cursor.to_list(length=None)\n",
    "    result[\"docs\"] = docs\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    elapsed = (t1 - t0) * 1000\n",
    "    log.debug(\"queried %d activities in %dms\", len(docs), elapsed)\n",
    "\n",
    "    if update_ts:\n",
    "        await index.update_many(\n",
    "            {\"_id\": {\"$in\": [a[ACTIVITY_ID] for a in docs]}},\n",
    "            {\"$set\": {TIMESTAMP: datetime.datetime.utcnow()}},\n",
    "        )\n",
    "        elapsed = (time.perf_counter() - t1) * 1000\n",
    "        log.debug(\"ts update in %dms\", elapsed)\n",
    "    return result\n",
    "\n",
    "\n",
    "def stats():\n",
    "    return DataAPIs.stats(COLLECTION_NAME)\n",
    "\n",
    "\n",
    "def drop():\n",
    "    return DataAPIs.drop(COLLECTION_NAME)\n",
    "\n",
    "\n",
    "ATYPE_SPECS = [\n",
    "    \"Ride\",\n",
    "    \"Run\",\n",
    "    \"Swim\",\n",
    "    \"Walk\",\n",
    "    \"Hike\",\n",
    "    \"Alpine Ski\",\n",
    "    \"Backcountry Ski\",\n",
    "    \"Canoe\",\n",
    "    \"Crossfit\",\n",
    "    \"E-Bike Ride\",\n",
    "    \"Elliptical\",\n",
    "    \"Handcycle\",\n",
    "    \"Ice Skate\",\n",
    "    \"Inline Skate\",\n",
    "    \"Kayak\",\n",
    "    \"Kitesurf Session\",\n",
    "    \"Nordic Ski\",\n",
    "    \"Rock Climb\",\n",
    "    \"Roller Ski\",\n",
    "    \"Row\",\n",
    "    \"Snowboard\",\n",
    "    \"Snowshoe\",\n",
    "    \"Stair Stepper\",\n",
    "    \"Stand Up Paddle\",\n",
    "    \"Surf\",\n",
    "    \"Velomobile \",\n",
    "    \"Virtual Ride\",\n",
    "    \"Virtual Run\",\n",
    "    \"Weight Training\",\n",
    "    \"Windsurf Session\",\n",
    "    \"Wheelchair\",\n",
    "    \"Workout\",\n",
    "    \"Yoga\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacac29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Strava ActivitySummary\n",
    "A = {'resource_state': 2,\n",
    " 'athlete': {'id': 15972102, 'resource_state': 1},\n",
    " 'name': 'Afternoon Shred',\n",
    " 'distance': 3301.7,\n",
    " 'moving_time': 1346,\n",
    " 'elapsed_time': 1378,\n",
    " 'total_elevation_gain': 50.1,\n",
    " 'type': 'Surfing',\n",
    " 'id': 6663463299,\n",
    " 'start_date': '2022-02-10T21:49:17Z',\n",
    " 'start_date_local': '2022-02-10T13:49:17Z',\n",
    " 'timezone': '(GMT-08:00) America/Los_Angeles',\n",
    " 'utc_offset': -28800.0,\n",
    " 'location_city': None,\n",
    " 'location_state': None,\n",
    " 'location_country': 'United States',\n",
    " 'achievement_count': 0,\n",
    " 'kudos_count': 0,\n",
    " 'comment_count': 0,\n",
    " 'athlete_count': 1,\n",
    " 'photo_count': 0,\n",
    " 'map': {'id': 'a6663463299',\n",
    "  'summary_polyline': 'cr{eFjowhVd@RVED]K[A[BMHKLAZBTJHAHGCEPK@k@LUFCVEP?DBL@DFd@FVNLCFIDCJWPMBa@G[O]EY?SBOd@a@FQBYH[AUIi@BQFILGNBPHNCh@WLARKDEBQCKBMNc@XMJBFH@f@Kr@c@lACN@XRf@?`@K`@@HDHZPV`@JFF@DIPCLg@NUn@YJALD\\\\N\\\\TF?HCN@JMVE@EBk@AWFYFIXSLGXENIJ]Jg@FKFCJHNVF^`@vANPLXRJJJP\\\\DDNBBERCF?FDVBHBHPBb@DTDfACz@Gp@IPHGBMAAGPORKZS\\\\e@~A_AXe@D]Cc@K_@OM?G@IJYhAMHi@Hc@TYHk@D[?g@LqAr@_@d@CRA\\\\Jl@?NEVOZWR_ANcAX[@QNO^CZ`@`BD`@@\\\\GnAQrAIb@OLI?GCKMGo@GSU]IU?UGQBc@EUe@o@Qm@E]RuBC[O_@IEMBUA]J{@^[DOASGEGIWIc@GMGEKA_@VQR{@|A]d@EBG?_@OKIQ@OCKIGY?i@DaBM]e@g@_@{@DYFQb@_ABWCMe@_@_@MSCs@Ps@Ce@?Cb@FC@FD@?E?BBB',\n",
    "  'resource_state': 2},\n",
    " 'trainer': False,\n",
    " 'commute': False,\n",
    " 'manual': False,\n",
    " 'private': False,\n",
    " 'visibility': 'everyone',\n",
    " 'flagged': False,\n",
    " 'gear_id': None,\n",
    " 'start_latlng': [37.829625, -122.18629333],\n",
    " 'end_latlng': [37.83219167, -122.187075],\n",
    " 'start_latitude': 37.829625,\n",
    " 'start_longitude': -122.187075,\n",
    " 'average_speed': 2.453,\n",
    " 'max_speed': 6.48,\n",
    " 'has_heartrate': True,\n",
    " 'average_heartrate': 115.2,\n",
    " 'max_heartrate': 142.0,\n",
    " 'heartrate_opt_out': False,\n",
    " 'display_hide_heartrate_option': True,\n",
    " 'elev_high': 428.1,\n",
    " 'elev_low': 353.1,\n",
    " 'upload_id': 7086217566,\n",
    " 'upload_id_str': '7086217566',\n",
    " 'external_id': '2022-02-10_22-13-35_2404963f-543a-485f-aca1-04e4184b7c08.tcx',\n",
    " 'from_accepted_tag': False,\n",
    " 'pr_count': 0,\n",
    " 'total_photo_count': 0,\n",
    " 'has_kudoed': False,\n",
    " 'suffer_score': 7.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f7c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=\"DEBUG\")\n",
    "log = logging.getLogger()\n",
    "\n",
    "await DataAPIs.connect()\n",
    "\n",
    "mongo_doc(**A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11958911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Users\n",
    "efrem = await Users.get(Users.ADMIN[0])\n",
    "efrem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = efrem[\"_id\"]\n",
    "asyncio.create_task(import_user_entries(**efrem))\n",
    "await asyncio.sleep(1)\n",
    "while await check_import_flag(_id):\n",
    "    await asyncio.sleep(0.5)\n",
    "    print(f\"Progress: {await check_import_flag(_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await query(after=\"2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd36873",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataAPIs\n",
    "await DataAPIs.stats(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "await DataAPIs.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataAPIs import db\n",
    "\n",
    "await DataAPIs.connect()\n",
    "await set_import_flag(2, \"hello\")\n",
    "x = await check_import_flag(2)\n",
    "await clear_import_flag(2)\n",
    "z = await check_import_flag(2)\n",
    "\n",
    "count = await count_user_entries(**efrem)\n",
    "\n",
    "has = await has_user_entries(**efrem)\n",
    "\n",
    "await DataAPIs.disconnect()\n",
    "\n",
    "x, z, count, has"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
