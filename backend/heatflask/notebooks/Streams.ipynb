{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eef44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are working in module directory\n",
    "repo_root = !git rev-parse --show-toplevel\n",
    "module_path = repo_root[0] + \"/backend/heatflask\"\n",
    "%cd $module_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f48dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile Streams.py\n",
    "\"\"\"\n",
    "***  For Jupyter notebook ***\n",
    "Paste one of these Jupyter magic directives to the top of a cell\n",
    " and run it, to do these things:\n",
    "    %%cython --annotate    # Compile and run the cell\n",
    "    %load Streams.py         # Load Streams.py file into this (empty) cell\n",
    "    %%writefile Streams.py   # Write the contents of this cell to Streams.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from logging import getLogger\n",
    "import numpy as np\n",
    "import msgpack\n",
    "import polyline\n",
    "\n",
    "import DataAPIs\n",
    "from DataAPIs import redis\n",
    "import Strava\n",
    "import StreamCodecs\n",
    "\n",
    "log = getLogger(__name__)\n",
    "log.propagate = True\n",
    "\n",
    "APP_NAME = \"heatflask\"\n",
    "COLLECTION_NAME = \"streams\"\n",
    "CACHE_PREFIX = \"S:\"\n",
    "\n",
    "SECS_IN_HOUR = 60 * 60\n",
    "SECS_IN_DAY = 24 * SECS_IN_HOUR\n",
    "\n",
    "MONGO_TTL = int(os.environ.get(\"MONGO_STREAMS_TTL\", 10)) * SECS_IN_DAY\n",
    "REDIS_TTL = int(os.environ.get(\"REDIS_STREAMS_TTL\", 4)) * SECS_IN_HOUR\n",
    "\n",
    "DATA = {}\n",
    "\n",
    "\n",
    "async def get_collection():\n",
    "    if \"col\" not in DATA:\n",
    "        DATA[\"col\"] = await DataAPIs.init_collection(\n",
    "            COLLECTION_NAME, ttl=MONGO_TTL, cache_prefix=CACHE_PREFIX\n",
    "        )\n",
    "    return DATA[\"col\"]\n",
    "\n",
    "POLYLINE_PRECISION = 6\n",
    "\n",
    "def encode_streams(activity_id, rjson):\n",
    "    return msgpack.packb(\n",
    "    {\n",
    "        \"id\": activity_id,\n",
    "        \"t\": StreamCodecs.rlld_encode(rjson[\"time\"][\"data\"]),\n",
    "        \"a\": StreamCodecs.rlld_encode(rjson[\"altitude\"][\"data\"]),\n",
    "        \"p\": polyline.encode(rjson[\"latlng\"][\"data\"], POLYLINE_PRECISION),\n",
    "    }\n",
    ")\n",
    "    \n",
    "def decode_streams(msgpacked_streams):\n",
    "    d = msgpack.unpackb(msgpacked_streams)\n",
    "    return {\n",
    "        \"id\": d[\"id\"],\n",
    "        \"time\": StreamCodecs.rlld_decode(d[\"t\"], dtype=\"u2\"),\n",
    "        \"altitude\": StreamCodecs.rlld_decode(d[\"a\"], dtype=\"i2\"),\n",
    "        \"latlng\": polyline.decode(d[\"p\"], POLYLINE_PRECISION),\n",
    "    }\n",
    "\n",
    "def mongo_doc(activity_id, stream_data, ts=None):\n",
    "    return {\n",
    "        \"_id\": int(activity_id),\n",
    "        \"mpk\": stream_data,\n",
    "        \"ts\": ts or datetime.datetime.now(),\n",
    "    }\n",
    "\n",
    "def cache_key(aid):\n",
    "    return f\"{CACHE_PREFIX}{aid}\"\n",
    "\n",
    "async def strava_import(activity_ids, **user):\n",
    "    uid = int(user[\"_id\"])\n",
    "    \n",
    "    strava = Strava.AsyncClient(uid, **user[\"auth\"])\n",
    "    await strava.update_access_token()\n",
    "    \n",
    "    coll = await get_collection()\n",
    "    \n",
    "    docs = []\n",
    "    now = datetime.datetime.now()\n",
    "    aiterator = strava.get_many_streams(activity_ids)\n",
    "    async for aid, streams in aiterator:\n",
    "        msgpacked = encode_streams(aid, streams)\n",
    "        abort_signal = yield aid, msgpacked\n",
    "        \n",
    "        try:\n",
    "            doc = mongo_doc(aid, msgpacked, ts=now)\n",
    "        except Exception as e:\n",
    "            log.error(\"Streams %s encode error: %s\", activity_id, e)\n",
    "        else:\n",
    "            docs.append(doc)\n",
    "            \n",
    "        if abort_signal:\n",
    "            await Strava.AsyncClient.abort(aiterator)\n",
    "            break\n",
    "    \n",
    "    # now store all this stuff in MongoDB (overwrite any existing records)\n",
    "    await delete([doc[\"_id\"] for doc in docs])\n",
    "    await coll.insert_many(docs)\n",
    "    # in Redis\n",
    "    async with redis.pipeline(transaction=True) as pipe:\n",
    "        for doc in docs:\n",
    "            pipe = pipe.setex(cache_key(doc[\"_id\"]), REDIS_TTL, doc['mpk'])\n",
    "        await pipe.execute()\n",
    "        \n",
    "\n",
    "async def aiter_query(activity_ids=None, user=None):\n",
    "    if not activity_ids:\n",
    "        return\n",
    "    \n",
    "    # First we check Redis cache\n",
    "    t0 = time.perf_counter()\n",
    "    keys = [cache_key(aid) for aid in activity_ids]\n",
    "    redis_response = await redis.mget(keys)\n",
    "    redis_result = list(filter(None, redis_response))\n",
    "    redis_result_keys = [keys[i] for i, r in enumerate(redis_response)]\n",
    "    \n",
    "    # Reset TTL for those cached streams that were hit \n",
    "    async with redis.pipeline(transaction=True) as pipe:\n",
    "        for k in redis_result_keys:\n",
    "            pipe = pipe.expire(k, REDIS_TTL)\n",
    "        await pipe.execute()\n",
    "        \n",
    "    t1 = time.perf_counter()\n",
    "    log.debug(\"retrieved %d streams from Redis in %d\", len(redis_result), (t1-t0)*1000)\n",
    "    local_result = list(redis_result)\n",
    "    \n",
    "    activity_ids = [activity_ids[i] for i, r in enumerate(redis_response) if not r]\n",
    "    if activity_ids:\n",
    "        \n",
    "        # Next we query MongoDB for any cache misses\n",
    "        t0 = time.perf_counter()\n",
    "        streams = await get_collection()\n",
    "        query = {\"_id\": {\"$in\": activity_ids}}\n",
    "        mongo_result = [(d[\"_id\"], d[\"mpk\"]) async for d in streams.find(query)]\n",
    "        local_result.extend(mongo_result)\n",
    "        mongo_result_ids = [_id for _id, mpk in mongo_result]\n",
    "        mongo_result_keys = [cache_key(aid) for aid in mongo_result_ids]\n",
    "        \n",
    "        # Cache the mongo hits\n",
    "        async with redis.pipeline(transaction=True) as pipe:\n",
    "            for k, s in zip(mongo_result_keys, mongo_result):\n",
    "                pipe = pipe.setex(k, REDIS_TTL, s)\n",
    "            await pipe.execute()\n",
    "        \n",
    "        # Update TTL for mongo hits\n",
    "        await streams.update_many(\n",
    "            {\"_id\": {\"$in\": mongo_result_ids}},\n",
    "            {\"$set\": {\"ts\": datetime.datetime.utcnow()}},\n",
    "        )\n",
    "        elapsed = (time.perf_counter() - t0) * 1000\n",
    "        log.debug(\"retrieved %d streams from Mongo in %d\", len(mongo_result), elapsed)\n",
    "        \n",
    "        activity_ids = list(set(activity_ids) - set(mongo_result_ids))\n",
    "    \n",
    "    streams_import = None\n",
    "    first_fetch = None\n",
    "    if activity_ids and (user is not None):\n",
    "        t0 = time.perf_counter()\n",
    "        streams_import = strava_import(activity_ids, **user)\n",
    "        first_fetch = asyncio.create_task(streams_import.__anext__())\n",
    "        \n",
    "    for item in local_result:\n",
    "        abort_signal = yield item\n",
    "        if abort_signal:\n",
    "            log.info(\"Local Streams query aborted\")\n",
    "            return\n",
    "    \n",
    "    if streams_import:\n",
    "        item1 = await first_fetch\n",
    "        abort_signal = yield item1\n",
    "        imported_items = [item1]\n",
    "        \n",
    "        if not abort_signal:\n",
    "            async for item in streams_import:\n",
    "                imported_items.append(item)\n",
    "                abort_signal = yield item\n",
    "                if abort_signal:\n",
    "                    break\n",
    "        \n",
    "        if abort_signal:\n",
    "            Strava.AsyncClient.abort(streams_import)\n",
    "            log.info(\"Remote Streams query aborted\")\n",
    "            \n",
    "        t1 = time.perf_counter()\n",
    "        log.debug(\"retrieved %d streams from Strava in %d\", len(imported_items), (t1-t0)*1000)\n",
    "        imported_ids = set(aid for aid, mpk in imported_items)\n",
    "        missing_ids = set(activity_ids) - imported_ids\n",
    "        if missing_ids:\n",
    "            log.info(\"unable to import streams for %s\", missing_ids)\n",
    "        \n",
    "\n",
    "async def query(**kwargs):\n",
    "    return [s async for s in aiter_query(**kwargs)]\n",
    "        \n",
    "async def delete(activity_ids):\n",
    "    streams = await get_collection()\n",
    "    return await streams.delete_many({\"_id\": {\"$in\": activity_ids}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f09182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=\"DEBUG\")\n",
    "\n",
    "N_FETCH = 15\n",
    "\n",
    "import Index\n",
    "result = await Index.query(limit=N_FETCH)\n",
    "activity_ids = [d[\"_id\"] for d in result[\"docs\"]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f3b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99733c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import Users\n",
    "import Strava\n",
    "\n",
    "admin = await Users.get(Users.ADMIN[0])\n",
    "admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4dec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = await query(activity_ids=activity_ids, user=admin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07f515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
